{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":11492517,"datasetId":7204092,"databundleVersionId":11939427}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"With this nodebook we intend to ingest a json list of AI related papers and output a summary by industry with the corresponding contributions we find within those papers. ","metadata":{}},{"cell_type":"code","source":"!pip install chromadb\n!pip install hdbscan\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:55:09.357133Z","iopub.execute_input":"2025-04-20T23:55:09.357944Z","iopub.status.idle":"2025-04-20T23:55:47.253159Z","shell.execute_reply.started":"2025-04-20T23:55:09.357916Z","shell.execute_reply":"2025-04-20T23:55:47.251998Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting chromadb\n  Downloading chromadb-1.0.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nCollecting build>=1.0.3 (from chromadb)\n  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.3)\nCollecting chroma-hnswlib==0.7.6 (from chromadb)\n  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\nCollecting fastapi==0.115.9 (from chromadb)\n  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\nCollecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\nCollecting posthog>=2.4.0 (from chromadb)\n  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.1)\nCollecting onnxruntime>=1.14.1 (from chromadb)\n  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\nCollecting pypika>=0.48.9 (from chromadb)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\nCollecting bcrypt>=4.0.1 (from chromadb)\n  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\nCollecting kubernetes>=28.1.0 (from chromadb)\n  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\nRequirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\nCollecting mmh3>=4.0.1 (from chromadb)\n  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\nRequirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (14.0.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\nCollecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\nCollecting pyproject_hooks (from build>=1.0.3->chromadb)\n  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.22.3)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\nRequirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\nRequirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\nCollecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2.4.1)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\nRequirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (75.1.0)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.67.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\nCollecting protobuf (from onnxruntime>=1.14.1->chromadb)\n  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nCollecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\nCollecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\nCollecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\nCollecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\nCollecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.30.2)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.5->chromadb) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.5->chromadb) (2024.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.5->chromadb) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\nDownloading chromadb-1.0.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\nDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\nDownloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\nDownloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\nDownloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\nDownloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading durationpy-0.9-py3-none-any.whl (3.5 kB)\nDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nDownloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\nDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53801 sha256=9ad8512a0dd28e07fc8370616fe2fbd2f4018a9856c455fca1b9b24ab6fe1775\n  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\nSuccessfully built pypika\nInstalling collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, protobuf, opentelemetry-util-http, mmh3, humanfriendly, httptools, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, onnxruntime, chroma-hnswlib, chromadb\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.16.0\n    Uninstalling opentelemetry-api-1.16.0:\n      Successfully uninstalled opentelemetry-api-1.16.0\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.16.0\n    Uninstalling opentelemetry-sdk-1.16.0:\n      Successfully uninstalled opentelemetry-sdk-1.16.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-1.0.5 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.9 httptools-0.6.4 humanfriendly-10.0 kubernetes-32.0.1 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.21.1 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 opentelemetry-util-http-0.53b1 posthog-3.25.0 protobuf-5.29.4 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.0 starlette-0.45.3 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5\nCollecting hdbscan\n  Downloading hdbscan-0.8.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\nRequirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.11/dist-packages (from hdbscan) (1.26.4)\nRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan) (1.15.2)\nRequirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.11/dist-packages (from hdbscan) (1.2.2)\nRequirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan) (1.4.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.20->hdbscan) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.20->hdbscan) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.20->hdbscan) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.20->hdbscan) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.20->hdbscan) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.20->hdbscan) (2.4.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20->hdbscan) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.20->hdbscan) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.20->hdbscan) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.20->hdbscan) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.20->hdbscan) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.20->hdbscan) (2024.2.0)\nDownloading hdbscan-0.8.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: hdbscan\nSuccessfully installed hdbscan-0.8.40\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import sys\nimport kagglehub \ngen_ai_capstone_utils_path = kagglehub.dataset_download('helgaguerreiro/gen-ai-capstone-utils')\nsys.path.append(gen_ai_capstone_utils_path)\n\nimport json \nimport os  \nfrom utils import lib \n\nprint(os.listdir(gen_ai_capstone_utils_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T00:01:18.791425Z","iopub.execute_input":"2025-04-21T00:01:18.791795Z","iopub.status.idle":"2025-04-21T00:01:22.131497Z","shell.execute_reply.started":"2025-04-21T00:01:18.791767Z","shell.execute_reply":"2025-04-21T00:01:22.130626Z"}},"outputs":[{"name":"stdout","text":"['utils', 'industry-list.json', 'papers_sample.json']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport google.generativeai as genai  \n#\n# Config \n#\nconfig = {\n    \"data_dir\": gen_ai_capstone_utils_path, # where we store the input data \n    \"out_dir\":\"/kaggle/working/\",# where we are outputing intermediate data and the final document \n    \"papers_file\":\"papers_sample.json\", # what paper list are we ingesting \n    \"GOOGLE_API_KEY\": UserSecretsClient().get_secret(\"GOOGLE_API_KEY\"),\n    \"reset\": True\n}\n\ngenai.configure(api_key=config['GOOGLE_API_KEY'])\npapers = [] \n\n# \n# load the papers by reading the data/papers_2025-03-23_2025-03-29.json file\n# if there's an intermediate file  load that one \nfilepath = os.path.join(config['data_dir'],config['papers_file'])\n\nif (config['reset']):\n  os.remove('/kaggle/working/papers_enriched.json')\n  os.remove('/kaggle/working/suspicious_classifications.json')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T00:03:13.533287Z","iopub.execute_input":"2025-04-21T00:03:13.533617Z","iopub.status.idle":"2025-04-21T00:03:13.697146Z","shell.execute_reply.started":"2025-04-21T00:03:13.533585Z","shell.execute_reply":"2025-04-21T00:03:13.696356Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Make sure we can restaure intermediate results if something goes wrong while testing changes ","metadata":{}},{"cell_type":"code","source":"import pandas as pd \n\nif  os.path.exists(os.path.join(config['out_dir'],'papers_enriched.json')):\n    filepath =  os.path.join(config['out_dir'],'papers_enriched.json')\n\nprint(\"Loading papers from:\", filepath)\nwith open(filepath, 'r') as f:\n    for line in f:\n        papers.append(json.loads(line))\n\npapers = pd.DataFrame(papers)\nprint(\"Loaded papers:\", len(papers))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T00:03:25.699314Z","iopub.execute_input":"2025-04-21T00:03:25.699921Z","iopub.status.idle":"2025-04-21T00:03:25.717986Z","shell.execute_reply.started":"2025-04-21T00:03:25.699899Z","shell.execute_reply":"2025-04-21T00:03:25.717199Z"}},"outputs":[{"name":"stdout","text":"Loading papers from: /kaggle/input/gen-ai-capstone-utils/papers_sample.json\nLoaded papers: 20\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"We want to ground the model output to a pre-defined set of industries. \n\nThe industry_meta contains \n* name - the industry name\n* keywords - keywords associated with the industry\n* examples - examples of what should match the industry\n\nWe will use this data to compose the prompt when querying the model. ","metadata":{}},{"cell_type":"code","source":"# Load the industry meta data from the data/industry-list.json file\nwith open(os.path.join(config['data_dir'], 'industry-list.json'), 'r') as f:\n    industry_meta = json.load(f)\n\nprint(industry_meta)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T00:03:28.762512Z","iopub.execute_input":"2025-04-21T00:03:28.763353Z","iopub.status.idle":"2025-04-21T00:03:28.771008Z","shell.execute_reply.started":"2025-04-21T00:03:28.763318Z","shell.execute_reply":"2025-04-21T00:03:28.770278Z"}},"outputs":[{"name":"stdout","text":"[{'industry': 'Healthcare', 'keywords': ['doctor', 'hospital', 'medical', 'imaging', 'diagnosis', 'clinical'], 'examples': ['Detecting tumors from MRI scans.']}, {'industry': 'Finance & Banking', 'keywords': ['finance', 'banking', 'fraud', 'credit', 'insurance', 'investment', 'stock'], 'examples': ['Predicting credit default risk using machine learning.']}, {'industry': 'Education', 'keywords': ['education', 'student', 'learning', 'tutoring', 'school', 'curriculum'], 'examples': ['AI tutor for personalized mathematics education.']}, {'industry': 'Energy & Utilities', 'keywords': ['energy', 'grid', 'power', 'electricity', 'utility'], 'examples': ['Forecasting power demand in smart grids.']}, {'industry': 'Retail & E-commerce', 'keywords': ['retail', 'shopping', 'e-commerce', 'consumer', 'purchase', 'sales'], 'examples': ['Optimizing product recommendations for online stores.']}, {'industry': 'Agriculture', 'keywords': ['agriculture', 'crop', 'farming', 'irrigation', 'soil'], 'examples': ['Predicting crop yields using satellite imagery.']}, {'industry': 'Transportation & Logistics', 'keywords': ['transportation', 'logistics', 'shipping', 'fleet', 'delivery', 'supply chain'], 'examples': ['Optimizing last-mile delivery routes using AI.']}, {'industry': 'Manufacturing', 'keywords': ['manufacturing', 'factory', 'production', 'supply chain', 'quality control'], 'examples': ['Detecting defects in manufacturing assembly lines.', 'Use of robotics and AI to automate production lines.', 'Using sensor data and AI to predict machine failures before they happen', 'Optimizing inventory, procurement, and logistics for raw materials and finished products', 'Integration of IoT devices, AI, and data analytics to create connected, flexible, and efficient manufacturing systems']}, {'industry': 'Environmental Science', 'keywords': ['climate', 'environment', 'conservation', 'wildlife', 'sustainability'], 'examples': ['Monitoring deforestation using satellite data.']}, {'industry': 'Geospatial & Remote Sensing', 'keywords': ['satellite', 'geospatial', 'earth observation', 'remote sensing', 'mapping'], 'examples': ['Mapping urban expansion from satellite images.']}, {'industry': 'Cybersecurity', 'keywords': ['cybersecurity', 'security', 'hacking', 'malware', 'phishing'], 'examples': ['Detecting phishing attempts in corporate emails.']}, {'industry': 'Legal', 'keywords': ['law', 'legal', 'compliance', 'regulation', 'litigation'], 'examples': ['Summarizing legal case documents with LLMs.']}, {'industry': 'Public Policy & Governance', 'keywords': ['policy', 'governance', 'government', 'regulation', 'society'], 'examples': ['Analyzing social policy impact using AI simulations.']}, {'industry': 'Social Sciences & Humanities', 'keywords': ['social', 'sociology', 'anthropology', 'history', 'language', 'philosophy'], 'examples': ['Studying language evolution patterns using NLP.']}, {'industry': 'Entertainment & Media', 'keywords': ['media', 'film', 'music', 'entertainment', 'game', 'animation'], 'examples': ['Generating background music using AI models.']}, {'industry': 'Construction & Real Estate', 'keywords': ['construction', 'real estate', 'building', 'architecture', 'urban planning'], 'examples': ['Predicting real estate price trends with machine learning.']}, {'industry': 'Aerospace & Defense', 'keywords': ['aerospace', 'satellite', 'aviation', 'space', 'defense', 'military'], 'examples': ['Optimizing satellite image analysis for defense applications.']}]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"To have the model assign an industry to a paper we should consider the following: \n*When using flash models, it is best to separate the task of deciding if it is an industry-relevant paper from the task of deciding which industry fits \n* Grounding the prompt helps in directing the model to specific names of industries but does not prevent the model from hallucinating \n* Flash models have poor abstraction capabilities and will often drift into inferring industry associations even at low temperatures; we should always check the output of the model to exclude hallucinations \n\n* We instruct the model to assign the category Other as a fallback if none of the given allowed categories match \n* When the flash model returns three or more categories, or it returns the category \"Other\" alongside other categories, we classify this as a \"suspicious classification\" and  use a pro model to re-run the prompt and replace the flash model's assessment\n\nimplementation is defined in utils/industry.py","metadata":{}},{"cell_type":"code","source":"from utils import industry \n# Run each papers through the model so we can assign an industry label \nindustry.classify_industry(papers,industry_meta,config['out_dir'])\nprint(papers.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T00:03:31.653531Z","iopub.execute_input":"2025-04-21T00:03:31.653828Z","iopub.status.idle":"2025-04-21T00:03:50.030621Z","shell.execute_reply.started":"2025-04-21T00:03:31.653806Z","shell.execute_reply":"2025-04-21T00:03:50.029781Z"}},"outputs":[{"name":"stdout","text":"################################################## \nℹ️ Saving intermediate results...\n\n\n ################################################## \nPaper 1/20: 2503.17894 Generative AI for Validating Physics Laws \n\n\nPaper is not related to industry development, skipping...\n\n\n ################################################## \nPaper 2/20: 2503.17896 Multi-Disease-Aware Training Strategy for Cardiac MR Image Segmentation \n\n\nPaper is not related to industry development, skipping...\n\n\n ################################################## \nPaper 3/20: 2503.17897 Real-time Global Illumination for Dynamic 3D Gaussian Scenes \n\n\nTime taken to query model: 0.9729924201965332 seconds\nIndustry list:\n [{'industry': 'Entertainment & Media', 'relevanceScore': 85, 'summary': 'The paper presents a real-time global illumination approach for dynamic 3D Gaussian models and meshes. This is relevant to the entertainment and media industry as it enables high-quality, real-time rendering of dynamic scenes with interactive materials and dynamic lighting, which is crucial for games, animation, and film.'}, {'industry': 'Construction & Real Estate', 'relevanceScore': 50, 'summary': 'The paper presents a real-time global illumination approach for dynamic 3D Gaussian models and meshes. This could be used to render building designs in real time, which could be useful in the construction and real estate industries.'}]\n\n\n\n\n\n ################################################## \nPaper 4/20: 2503.17899 What Time Tells Us? An Explorative Study of Time Awareness Learned from\n  Static Images \n\n\nPaper is not related to industry development, skipping...\n\n\n ################################################## \nPaper 5/20: 2503.17900 MedPlan:A Two-Stage RAG-Based System for Personalized Medical Plan\n  Generation \n\n\nTime taken to query model: 0.6348521709442139 seconds\nIndustry list:\n [{'industry': 'Healthcare', 'relevanceScore': 90, 'summary': 'The paper focuses on generating personalized medical plans using LLMs, addressing the limitations of current systems in treatment planning from electronic health records. It proposes a two-stage RAG-based system (MedPlan) that aligns with clinical workflows and improves assessment accuracy and treatment plan quality.'}]\n\n\n\n\n\n ################################################## \nPaper 6/20: 2503.17903 GLADMamba: Unsupervised Graph-Level Anomaly Detection Powered by\n  Selective State Space Model \n\n\nTime taken to query model: 1.1971731185913086 seconds\nIndustry list:\n [{'industry': 'Healthcare', 'relevanceScore': 85, 'summary': 'The paper introduces GLADMamba, a novel framework for unsupervised graph-level anomaly detection (UGLAD), with applications in anti-cancer drug discovery. It improves anomaly detection by using a selective state space model to capture long-range dependencies and spectral information, which is useful in the healthcare domain for identifying anomalies in complex biological networks and drug discovery processes.'}, {'industry': 'Social Sciences & Humanities', 'relevanceScore': 75, 'summary': 'The paper introduces GLADMamba, a novel framework for unsupervised graph-level anomaly detection (UGLAD), with applications in social network analysis. It improves anomaly detection by using a selective state space model to capture long-range dependencies and spectral information, which is useful in the social sciences domain for identifying anomalies in complex social networks.'}]\n\n\n\n\n\n ################################################## \nPaper 7/20: 2503.17905 Finding Stable Subnetworks at Initialization with Dataset Distillation \n\n\nPaper is not related to industry development, skipping...\n\n\n ################################################## \nPaper 8/20: 2503.17907 Guided Diffusion for the Extension of Machine Vision to Human Visual\n  Perception \n\n\nTime taken to query model: 1.2731504440307617 seconds\nIndustry list:\n [{'industry': 'Entertainment & Media', 'relevanceScore': 75, 'summary': 'The paper discusses image compression techniques focused on both human perception and machine vision, with the goal of generating human-viewable images from compressed data using diffusion models. This is relevant to the Entertainment & Media industry because efficient image compression and generation are crucial for media streaming, content creation, and distribution, ultimately impacting user experience and cost-effectiveness.'}, {'industry': 'Geospatial & Remote Sensing', 'relevanceScore': 50, 'summary': 'While the abstract does not explicitly mention geospatial applications, image compression and efficient storage/transmission are generally relevant to remote sensing and satellite imagery, as they deal with large image datasets. The focus of the paper on image compression techniques could find relevance in handling satellite or aerial imagery.'}]\n\n\n\n\n\n ################################################## \nPaper 9/20: 2503.17908 Does GCL Need a Large Number of Negative Samples? Enhancing Graph\n  Contrastive Learning with Effective and Efficient Negative Sampling \n\n\nPaper is not related to industry development, skipping...\n\n\n ################################################## \nPaper 10/20: 2503.17909 Financial Wind Tunnel: A Retrieval-Augmented Market Simulator \n\n\nTime taken to query model: 0.661095380783081 seconds\nIndustry list:\n [{'industry': 'Finance & Banking', 'relevanceScore': 95, 'summary': 'The paper focuses on developing a market simulator for generating synthetic financial data, enhancing model development, and enabling stress testing for improved returns and risk control in complex market conditions. The core focus is on financial markets and applications of simulation in finance and banking.'}]\n\n\n\n\n\n ################################################## \nPaper 11/20: 2503.17914 Semi-supervised Semantic Segmentation with Multi-Constraint Consistency\n  Learning \n\n\nPaper is not related to industry development, skipping...\n\n\n ################################################## \nPaper 12/20: 2503.17915 Cat-AIR: Content and Task-Aware All-in-One Image Restoration \n\n\nPaper is not related to industry development, skipping...\n\n\n ################################################## \nPaper 13/20: 2503.17919 Predicting performance-related properties of refrigerant based on\n  tailored small-molecule functional group contribution \n\n\nTime taken to query model: 1.409775733947754 seconds\nIndustry list:\n [{'industry': 'Energy & Utilities', 'relevanceScore': 85, 'summary': 'This paper focuses on predicting the performance-related properties of refrigerants, which are crucial for the design and optimization of refrigeration systems. Refrigeration systems are extensively used in the energy and utilities sector for various applications like cooling power plants, maintaining temperature in data centers, and transporting liquefied natural gas. The paper proposes a tailored group contribution (GC) method combined with machine learning to model key properties related to the operational efficiency of refrigeration systems, such as normal boiling point, critical temperature, critical pressure, enthalpy of vaporization, and acentric factor. This research has the potential to improve the efficiency and performance of refrigeration systems used in the energy and utilities industry, by enabling better refrigerant design and selection.'}, {'industry': 'Manufacturing', 'relevanceScore': 50, 'summary': 'Refrigeration is used in some manufacturing processes, especially food related. The paper has a possible contribution to better selection of refrigerants in these use cases.'}]\n\n\n\n\n\n ################################################## \nPaper 14/20: 2503.17922 WindowKV: Task-Adaptive Group-Wise KV Cache Window Selection for\n  Efficient LLM Inference \n\n\nTime taken to query model: 1.067589282989502 seconds\nIndustry list:\n [{'industry': 'Other', 'relevanceScore': 40, 'summary': \"This paper presents a method for compressing the KV cache in large language models (LLMs) to improve inference efficiency, particularly in long-context scenarios. While it doesn't directly fall into any of the predefined industries, the focus on efficient LLM inference could be relevant to various industries that utilize LLMs, such as those using LLMs for legal document summarization or medical diagnosis, but this is not explicitly stated.\", 'reasoning': \"The paper discusses KV cache compression for LLMs, a technique relevant to efficient LLM inference.  The application of LLMs isn't specified to any particular industry. The mention of industrial scenarios is vague.\"}]\n\n\n\n\n\n ################################################## \nPaper 15/20: 2503.17924 WLB-LLM: Workload-Balanced 4D Parallelism for Large Language Model\n  Training \n\n\nTime taken to query model: 0.6405742168426514 seconds\nIndustry list:\n [{'industry': 'Other', 'relevanceScore': 10, 'summary': 'The paper focuses on improving the efficiency of large language model training using 4D parallelism, primarily addressing workload imbalance issues. It does not directly target any specific industry application but rather aims to optimize the training process itself.'}]\n\n\n\n\n\n ################################################## \nPaper 16/20: 2503.17928 Debiasing Multimodal Large Language Models via Noise-Aware Preference\n  Optimization \n\n\nPaper is not related to industry development, skipping...\n\n\n ################################################## \nPaper 17/20: 2503.17932 STShield: Single-Token Sentinel for Real-Time Jailbreak Detection in\n  Large Language Models \n\n\nTime taken to query model: 0.7501826286315918 seconds\nIndustry list:\n [{'industry': 'Cybersecurity', 'relevanceScore': 90, 'summary': 'The paper addresses the vulnerability of Large Language Models (LLMs) to jailbreak attacks, which is a significant cybersecurity concern. It proposes a lightweight framework, STShield, for real-time detection of these attacks. This directly contributes to enhancing the security and robustness of LLMs against malicious attempts to bypass their safety mechanisms.'}]\n\n\n\n\n\n ################################################## \nPaper 18/20: 2503.17933 Experience Retrieval-Augmentation with Electronic Health Records Enables\n  Accurate Discharge QA \n\n\nTime taken to query model: 0.9216604232788086 seconds\nIndustry list:\n [{'industry': 'Healthcare', 'relevanceScore': 95, 'summary': \"This paper focuses on improving the reliability of Large Language Models (LLMs) in clinical applications by using retrieval-augmented generation (RAG) with Electronic Health Records (EHR). It introduces a framework called ExpRAG that retrieves relevant context from other patients' discharge reports to enhance medical reasoning. The paper also introduces a new clinical QA dataset called DischargeQA for evaluation. This is highly relevant to the healthcare industry as it directly addresses improving the accuracy and reliability of AI in medical applications, specifically for discharge quality assurance.\"}]\n\n\n\n\n\n ################################################## \nPaper 19/20: 2503.17934 TransAnimate: Taming Layer Diffusion to Generate RGBA Video \n\n\nTime taken to query model: 0.826042890548706 seconds\nIndustry list:\n [{'industry': 'Entertainment & Media', 'relevanceScore': 90, 'summary': 'The paper focuses on generating RGBA videos with alpha channels for transparency and visual effects. It mentions applications in gaming and visual effects, indicating a strong connection to the entertainment and media industry.'}, {'industry': 'Game', 'relevanceScore': 90, 'summary': 'The paper focuses on generating RGBA videos with alpha channels for transparency and visual effects. It mentions applications in gaming and visual effects, indicating a strong connection to the game industry.'}]\n\n\n\n\n\n ################################################## \nPaper 20/20: 2503.17935 Dataset Distillation for Quantum Neural Networks \n\n\nPaper is not related to industry development, skipping...\n\n\n ##################################################\nNumber of suspicious classifications: 0\nNumber of fixed classifications: 0\nNumber of papers processed: 20\n           id                                              title  \\\n0  2503.17894          Generative AI for Validating Physics Laws   \n1  2503.17896  Multi-Disease-Aware Training Strategy for Card...   \n2  2503.17897  Real-time Global Illumination for Dynamic 3D G...   \n3  2503.17899  What Time Tells Us? An Explorative Study of Ti...   \n4  2503.17900  MedPlan:A Two-Stage RAG-Based System for Perso...   \n5  2503.17903  GLADMamba: Unsupervised Graph-Level Anomaly De...   \n6  2503.17905  Finding Stable Subnetworks at Initialization w...   \n7  2503.17907  Guided Diffusion for the Extension of Machine ...   \n8  2503.17908  Does GCL Need a Large Number of Negative Sampl...   \n9  2503.17909  Financial Wind Tunnel: A Retrieval-Augmented M...   \n\n                                            abstract        date  \\\n0    We present generative artificial intelligenc...  2025-03-23   \n1    Accurate segmentation of the ventricles from...  2025-03-23   \n2    We present a real-time global illumination a...  2025-03-23   \n3    Time becomes visible through illumination ch...  2025-03-23   \n4    Despite recent success in applying large lan...  2025-03-23   \n5    Unsupervised graph-level anomaly detection (...  2025-03-23   \n6    Recent works have shown that Dataset Distill...  2025-03-23   \n7    Image compression technology eliminates redu...  2025-03-23   \n8    Graph Contrastive Learning (GCL) aims to sel...  2025-03-23   \n9    Market simulator tries to create high-qualit...  2025-03-23   \n\n                                       industry_list  \n0  [{'industry': 'N/A', 'relevanceScore': 0, 'sum...  \n1  [{'industry': 'N/A', 'relevanceScore': 0, 'sum...  \n2  [{'industry': 'Entertainment & Media', 'releva...  \n3  [{'industry': 'N/A', 'relevanceScore': 0, 'sum...  \n4  [{'industry': 'Healthcare', 'relevanceScore': ...  \n5  [{'industry': 'Healthcare', 'relevanceScore': ...  \n6  [{'industry': 'N/A', 'relevanceScore': 0, 'sum...  \n7  [{'industry': 'Entertainment & Media', 'releva...  \n8  [{'industry': 'N/A', 'relevanceScore': 0, 'sum...  \n9  [{'industry': 'Finance & Banking', 'relevanceS...  \n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"\n# What % of papers are industry related , select those with industry N/A\nindustry_related = papers[\n    papers['industry_list'].apply(lambda x: len(x) > 0 and x[0]['industry'] != 'N/A')\n]\nprint(\"Papers related to industry development:\", len(industry_related))\nprint(\"Percentage of papers related to industry development:\", len(industry_related)/len(papers)*100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T00:04:10.891519Z","iopub.execute_input":"2025-04-21T00:04:10.892312Z","iopub.status.idle":"2025-04-21T00:04:10.900810Z","shell.execute_reply.started":"2025-04-21T00:04:10.892267Z","shell.execute_reply":"2025-04-21T00:04:10.899955Z"}},"outputs":[{"name":"stdout","text":"Papers related to industry development: 11\nPercentage of papers related to industry development: 55.00000000000001\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Some industries will contain many papers; every summary implies information compression. We can increase resolution without exploding the summary size if we can cluster similar papers and evaluate each cluster separately. \n\nTo cluster papers together, first, we create semantic embedings. ","metadata":{}},{"cell_type":"code","source":"import google.genai as genai_embed\nfrom utils import embedings\n\ncollection = lib.get_chroma_collection(name=\"paper_abstracts\", base_path=config['out_dir'])\nsample_embeding = lib.get_chroma_record(collection,'2504.01981__Manufacturing')\nif sample_embeding is not None:\n    print(\"\\n\\n#\" * 20, \"ChromaDB collection already exists. Skipping embedding.\", sample_embeding )\nelse:\n    print(\"\\n\\n\",\"#\" * 20, \"Embedding papers.\", sample_embeding)\n    client = genai_embed.Client(api_key=config['GOOGLE_API_KEY']) \n    embedings.embed_papers(client,papers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T00:05:08.590850Z","iopub.execute_input":"2025-04-21T00:05:08.591143Z","iopub.status.idle":"2025-04-21T00:05:11.341049Z","shell.execute_reply.started":"2025-04-21T00:05:08.591122Z","shell.execute_reply":"2025-04-21T00:05:11.340158Z"}},"outputs":[{"name":"stdout","text":"\n\n #################### Embedding papers. None\n✅ Collection 'paper_abstracts' contains 0 items.\n🧠 Found 9 industries to embed.\n\\n🛠️ Embedding 3 papers for industry: Entertainment & Media\n🚀 Embedding 3 papers for Entertainment & Media: ['2503.17897__Entertainment & Media', '2503.17907__Entertainment & Media', '2503.17934__Entertainment & Media']\n\\n🛠️ Embedding 1 papers for industry: Construction & Real Estate\n🚀 Embedding 1 papers for Construction & Real Estate: ['2503.17897__Construction & Real Estate']\n\\n🛠️ Embedding 3 papers for industry: Healthcare\n🚀 Embedding 3 papers for Healthcare: ['2503.17900__Healthcare', '2503.17903__Healthcare', '2503.17933__Healthcare']\n\\n🛠️ Embedding 1 papers for industry: Social Sciences & Humanities\n🚀 Embedding 1 papers for Social Sciences & Humanities: ['2503.17903__Social Sciences & Humanities']\n\\n🛠️ Embedding 1 papers for industry: Geospatial & Remote Sensing\n🚀 Embedding 1 papers for Geospatial & Remote Sensing: ['2503.17907__Geospatial & Remote Sensing']\n\\n🛠️ Embedding 1 papers for industry: Finance & Banking\n🚀 Embedding 1 papers for Finance & Banking: ['2503.17909__Finance & Banking']\n\\n🛠️ Embedding 1 papers for industry: Energy & Utilities\n🚀 Embedding 1 papers for Energy & Utilities: ['2503.17919__Energy & Utilities']\n\\n🛠️ Embedding 1 papers for industry: Manufacturing\n🚀 Embedding 1 papers for Manufacturing: ['2503.17919__Manufacturing']\n\\n🛠️ Embedding 1 papers for industry: Cybersecurity\n🚀 Embedding 1 papers for Cybersecurity: ['2503.17932__Cybersecurity']\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"The goal is to create 1 section per industry. \n\nEach section contains multiple clusters and one “General Outlook\" summary representing the papers that did not fit any clusters. \n\nWe also ask the model to assign a representative title for each cluster.","metadata":{}},{"cell_type":"code","source":"from utils import summary\nsummary.get_summaries(papers,config['out_dir'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T00:05:26.192024Z","iopub.execute_input":"2025-04-21T00:05:26.193009Z","iopub.status.idle":"2025-04-21T00:07:16.612946Z","shell.execute_reply.started":"2025-04-21T00:05:26.192981Z","shell.execute_reply":"2025-04-21T00:07:16.612130Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"🧠 Found 11 industries to summarize. ['N/A', 'Entertainment & Media', 'Other', 'Finance & Banking', 'Healthcare', 'Manufacturing', 'Social Sciences & Humanities', 'Energy & Utilities', 'Construction & Real Estate', 'Cybersecurity', 'Geospatial & Remote Sensing']\n\n\nSummarizing industry: Entertainment & Media \nget_sections for industry: Entertainment & Media\n\n\nClustering papers for industry: Entertainment & Media\n           id               industry\n0  2503.17897  Entertainment & Media\n1  2503.17907  Entertainment & Media\n2  2503.17934  Entertainment & Media\n🧠 Found 3 papers for industry: Entertainment & Media with 1 clusters\nCluster -1 has 3 papers  ['2503.17897', '2503.17907', '2503.17934']\nSmall cluster, summarizing directly\nSummarizing batch of papers 3  papers\nget_cluster_summary prompt: 4617\nTitle: AI Innovations for High-Fidelity and Efficient Media in Entertainment\nreturning sections  [{'title': 'General Outlook', 'summary': \"These studies highlight AI's role in advancing media creation and processing for entertainment. A common thread is the use of novel AI techniques, including generative models like diffusion and 3D Gaussian representations, to enhance visual content. Key contributions focus on generating higher-quality, more realistic, and specialized media formats, such as dynamic 3D scenes with complex lighting, human-perceivable images derived from machine-optimized data, and videos incorporating transparency for visual effects. The research emphasizes improving efficiency, enabling real-time performance in rendering and optimizing data transmission through scalable coding. Furthermore, these approaches offer enhanced control and integration capabilities, bridging different data types or generation methods to meet specific industry demands in areas like gaming, visual effects, and content delivery.\", 'papers': [{'id': '2503.17897', 'summary': 'The paper presents a real-time global illumination approach for dynamic 3D Gaussian models and meshes. This is relevant to the entertainment and media industry as it enables high-quality, real-time rendering of dynamic scenes with interactive materials and dynamic lighting, which is crucial for games, animation, and film.', 'title': 'Real-time Global Illumination for Dynamic 3D Gaussian Scenes'}, {'id': '2503.17907', 'summary': 'The paper discusses image compression techniques focused on both human perception and machine vision, with the goal of generating human-viewable images from compressed data using diffusion models. This is relevant to the Entertainment & Media industry because efficient image compression and generation are crucial for media streaming, content creation, and distribution, ultimately impacting user experience and cost-effectiveness.', 'title': 'Guided Diffusion for the Extension of Machine Vision to Human Visual\\n  Perception'}, {'id': '2503.17934', 'summary': 'The paper focuses on generating RGBA videos with alpha channels for transparency and visual effects. It mentions applications in gaming and visual effects, indicating a strong connection to the entertainment and media industry.', 'title': 'TransAnimate: Taming Layer Diffusion to Generate RGBA Video'}]}]\n\n\nSummarizing industry: Finance & Banking \nget_sections for industry: Finance & Banking\n\n\nClustering papers for industry: Finance & Banking\n           id           industry\n0  2503.17909  Finance & Banking\n🧠 Found 1 papers for industry: Finance & Banking with 1 clusters\nCluster -1 has 1 papers  ['2503.17909']\nSmall cluster, summarizing directly\nSummarizing batch of papers 1  papers\nget_cluster_summary prompt: 2062\nTitle: Enhancing Financial Modeling and Risk Management via Advanced Market Simulation\nreturning sections  [{'title': 'General Outlook', 'summary': 'These research efforts contribute significantly to Finance & Banking by advancing the generation and application of synthetic market data. They employ sophisticated generative techniques, like diffusion models enhanced with retrieval methods, to create highly realistic, adaptable, and controllable market simulations across various conditions and frequencies. This addresses limitations of real-world data availability and the specificity of existing simulators. The core impact lies in enabling more robust development, testing, and optimization of downstream quantitative models, such as trading algorithms or risk assessment tools. By allowing for stress testing and the exploration of specific \"what-if\" scenarios within these advanced simulations, particularly under volatile or unprecedented conditions, the research aims to improve model performance, adaptability, and overall risk management within the financial sector.', 'papers': [{'id': '2503.17909', 'summary': 'The paper focuses on developing a market simulator for generating synthetic financial data, enhancing model development, and enabling stress testing for improved returns and risk control in complex market conditions. The core focus is on financial markets and applications of simulation in finance and banking.', 'title': 'Financial Wind Tunnel: A Retrieval-Augmented Market Simulator'}]}]\n\n\nSummarizing industry: Healthcare \nget_sections for industry: Healthcare\n\n\nClustering papers for industry: Healthcare\n     industry          id\n0  Healthcare  2503.17900\n1  Healthcare  2503.17903\n2  Healthcare  2503.17933\n🧠 Found 3 papers for industry: Healthcare with 1 clusters\nCluster -1 has 3 papers  ['2503.17900', '2503.17903', '2503.17933']\nSmall cluster, summarizing directly\nSummarizing batch of papers 3  papers\nget_cluster_summary prompt: 4452\nTitle: Enhancing Healthcare AI through Contextual Reasoning and Advanced Models\nreturning sections  [{'title': 'General Outlook', 'summary': \"These research efforts commonly contribute novel AI frameworks and methods to improve clinical relevance and performance in healthcare. They utilize advanced models like Large Language Models (LLMs) and State Space Models to tackle specific challenges. A shared focus is enhancing AI's reasoning capabilities by incorporating deeper context. This includes structuring AI workflows to better align with clinical practices (e.g., sequential reasoning for treatment planning) and integrating patient-specific information or similar case experiences derived from Electronic Health Records (EHRs) via techniques like retrieval-augmented generation (RAG). By moving beyond general knowledge or simplistic processing, these approaches aim to make AI outputs more accurate, reliable, and grounded in real-world clinical data, ultimately improving applications like treatment planning, medical question answering, and anomaly detection in biomedical data.\", 'papers': [{'id': '2503.17900', 'summary': 'The paper focuses on generating personalized medical plans using LLMs, addressing the limitations of current systems in treatment planning from electronic health records. It proposes a two-stage RAG-based system (MedPlan) that aligns with clinical workflows and improves assessment accuracy and treatment plan quality.', 'title': 'MedPlan:A Two-Stage RAG-Based System for Personalized Medical Plan\\n  Generation'}, {'id': '2503.17903', 'summary': 'The paper introduces GLADMamba, a novel framework for unsupervised graph-level anomaly detection (UGLAD), with applications in anti-cancer drug discovery. It improves anomaly detection by using a selective state space model to capture long-range dependencies and spectral information, which is useful in the healthcare domain for identifying anomalies in complex biological networks and drug discovery processes.', 'title': 'GLADMamba: Unsupervised Graph-Level Anomaly Detection Powered by\\n  Selective State Space Model'}, {'id': '2503.17933', 'summary': \"This paper focuses on improving the reliability of Large Language Models (LLMs) in clinical applications by using retrieval-augmented generation (RAG) with Electronic Health Records (EHR). It introduces a framework called ExpRAG that retrieves relevant context from other patients' discharge reports to enhance medical reasoning. The paper also introduces a new clinical QA dataset called DischargeQA for evaluation. This is highly relevant to the healthcare industry as it directly addresses improving the accuracy and reliability of AI in medical applications, specifically for discharge quality assurance.\", 'title': 'Experience Retrieval-Augmentation with Electronic Health Records Enables\\n  Accurate Discharge QA'}]}]\n\n\nSummarizing industry: Manufacturing \nget_sections for industry: Manufacturing\n\n\nClustering papers for industry: Manufacturing\n        industry          id\n0  Manufacturing  2503.17919\n🧠 Found 1 papers for industry: Manufacturing with 1 clusters\nCluster -1 has 1 papers  ['2503.17919']\nSmall cluster, summarizing directly\nSummarizing batch of papers 1  papers\nget_cluster_summary prompt: 1617\nTitle: Leveraging Machine Learning for Predictive Material Design in Manufacturing\nreturning sections  [{'title': 'General Outlook', 'summary': 'This research applies Machine Learning (ML), often integrated with domain-specific methods like Group Contribution (GC), to improve material design relevant to manufacturing. The core contribution involves developing tailored predictive models for key physical properties of specific substances, such as refrigerants. By utilizing curated databases and specialized ML models, this approach enables more accurate property prediction compared to general methods. This enhanced capability accelerates the design of novel materials and optimizes the performance of associated industrial systems, fostering efficiency and innovation within manufacturing contexts.', 'papers': [{'id': '2503.17919', 'summary': 'Refrigeration is used in some manufacturing processes, especially food related. The paper has a possible contribution to better selection of refrigerants in these use cases.', 'title': 'Predicting performance-related properties of refrigerant based on\\n  tailored small-molecule functional group contribution'}]}]\n\n\nSummarizing industry: Social Sciences & Humanities \nget_sections for industry: Social Sciences & Humanities\n\n\nClustering papers for industry: Social Sciences & Humanities\n           id                      industry\n0  2503.17903  Social Sciences & Humanities\n🧠 Found 1 papers for industry: Social Sciences & Humanities with 1 clusters\nCluster -1 has 1 papers  ['2503.17903']\nSmall cluster, summarizing directly\nSummarizing batch of papers 1  papers\nget_cluster_summary prompt: 2000\nTitle: AI-Driven Anomaly Detection Enhancing Social Network Analysis\nreturning sections  [{'title': 'General Outlook', 'summary': 'This research contributes advanced AI techniques for graph-level anomaly detection, directly applicable to social network analysis within the Social Sciences. By introducing methods like selective state space models (Mamba) combined with spectral information analysis, it offers enhanced capabilities for identifying unusual patterns, outliers, or structural deviations in complex network data. This advancement provides social scientists with more powerful computational tools to analyze large-scale social structures, potentially revealing hidden dynamics, influential nodes, or anomalous group behaviors that might be missed by traditional methods. The core contribution lies in improving the technical capacity for network analysis relevant to SSH research.', 'papers': [{'id': '2503.17903', 'summary': 'The paper introduces GLADMamba, a novel framework for unsupervised graph-level anomaly detection (UGLAD), with applications in social network analysis. It improves anomaly detection by using a selective state space model to capture long-range dependencies and spectral information, which is useful in the social sciences domain for identifying anomalies in complex social networks.', 'title': 'GLADMamba: Unsupervised Graph-Level Anomaly Detection Powered by\\n  Selective State Space Model'}]}]\n\n\nSummarizing industry: Energy & Utilities \nget_sections for industry: Energy & Utilities\n\n\nClustering papers for industry: Energy & Utilities\n             industry          id\n0  Energy & Utilities  2503.17919\n🧠 Found 1 papers for industry: Energy & Utilities with 1 clusters\nCluster -1 has 1 papers  ['2503.17919']\nSmall cluster, summarizing directly\nSummarizing batch of papers 1  papers\nget_cluster_summary prompt: 1627\nTitle: AI-Enhanced Material Property Prediction for Energy Efficiency\nreturning sections  [{'title': 'General Outlook', 'summary': 'Research integrates machine learning (ML) with domain-specific methods, like group contribution (GC), to enhance the prediction of material properties critical to the Energy & Utilities sector. By tailoring models specifically for relevant substances, such as refrigerants, this approach overcomes limitations of general predictive methods, leading to more accurate estimations for specific molecule types. The common contribution lies in developing specialized AI-driven tools that accurately forecast key performance-related properties (e.g., boiling point, critical parameters). This improved predictive capability directly supports the design and discovery of novel materials and the optimization of energy systems, ultimately aiming to improve operational efficiency within the sector.', 'papers': [{'id': '2503.17919', 'summary': 'This paper focuses on predicting the performance-related properties of refrigerants, which are crucial for the design and optimization of refrigeration systems. Refrigeration systems are extensively used in the energy and utilities sector for various applications like cooling power plants, maintaining temperature in data centers, and transporting liquefied natural gas. The paper proposes a tailored group contribution (GC) method combined with machine learning to model key properties related to the operational efficiency of refrigeration systems, such as normal boiling point, critical temperature, critical pressure, enthalpy of vaporization, and acentric factor. This research has the potential to improve the efficiency and performance of refrigeration systems used in the energy and utilities industry, by enabling better refrigerant design and selection.', 'title': 'Predicting performance-related properties of refrigerant based on\\n  tailored small-molecule functional group contribution'}]}]\n\n\nSummarizing industry: Construction & Real Estate \nget_sections for industry: Construction & Real Estate\n\n\nClustering papers for industry: Construction & Real Estate\n                     industry          id\n0  Construction & Real Estate  2503.17897\n🧠 Found 1 papers for industry: Construction & Real Estate with 1 clusters\nCluster -1 has 1 papers  ['2503.17897']\nSmall cluster, summarizing directly\nSummarizing batch of papers 1  papers\nget_cluster_summary prompt: 1610\nTitle: Advancing Real-Time 3D Visualization for Construction & Real Estate\nreturning sections  [{'title': 'General Outlook', 'summary': 'AI research contributes significantly to enhancing real-time 3D visualization capabilities applicable to the Construction and Real Estate industries. Key advancements focus on developing high-fidelity rendering techniques, such as real-time global illumination for complex 3D models including meshes and newer representations like 3D Gaussians. These methods enable the creation of dynamic, interactive digital environments where lighting conditions and material properties can be manipulated in real-time. This improves the realism and usability of architectural visualizations, virtual property tours, design simulations, and digital twins, facilitating better design exploration, stakeholder communication, and project understanding by providing high-performance, interactive rendering of complex scenes.', 'papers': [{'id': '2503.17897', 'summary': 'The paper presents a real-time global illumination approach for dynamic 3D Gaussian models and meshes. This could be used to render building designs in real time, which could be useful in the construction and real estate industries.', 'title': 'Real-time Global Illumination for Dynamic 3D Gaussian Scenes'}]}]\n\n\nSummarizing industry: Cybersecurity \nget_sections for industry: Cybersecurity\n\n\nClustering papers for industry: Cybersecurity\n        industry          id\n0  Cybersecurity  2503.17932\n🧠 Found 1 papers for industry: Cybersecurity with 1 clusters\nCluster -1 has 1 papers  ['2503.17932']\nSmall cluster, summarizing directly\nSummarizing batch of papers 1  papers\nget_cluster_summary prompt: 1554\nTitle: Lightweight Defense Mechanism for LLM Jailbreak Detection\nreturning sections  [{'title': 'General Outlook', 'summary': \"This research contributes an efficient, integrated defense mechanism for Large Language Models (LLMs) against jailbreak attacks. The core innovation is a lightweight framework enabling real-time detection of malicious prompts designed to bypass safety protocols. By leveraging the LLM's inherent capabilities via a novel single-token sentinel mechanism and combining supervised fine-tuning with adversarial training, the approach effectively identifies diverse jailbreak attempts. This method provides robust protection while preserving the LLM's utility on legitimate tasks and minimizing computational overhead. It offers a practical solution for enhancing the security and trustworthiness of deployed LLMs, addressing a critical vulnerability in AI systems relevant to cybersecurity.\", 'papers': [{'id': '2503.17932', 'summary': 'The paper addresses the vulnerability of Large Language Models (LLMs) to jailbreak attacks, which is a significant cybersecurity concern. It proposes a lightweight framework, STShield, for real-time detection of these attacks. This directly contributes to enhancing the security and robustness of LLMs against malicious attempts to bypass their safety mechanisms.', 'title': 'STShield: Single-Token Sentinel for Real-Time Jailbreak Detection in\\n  Large Language Models'}]}]\n\n\nSummarizing industry: Geospatial & Remote Sensing \nget_sections for industry: Geospatial & Remote Sensing\n\n\nClustering papers for industry: Geospatial & Remote Sensing\n           id                     industry\n0  2503.17907  Geospatial & Remote Sensing\n🧠 Found 1 papers for industry: Geospatial & Remote Sensing with 1 clusters\nCluster -1 has 1 papers  ['2503.17907']\nSmall cluster, summarizing directly\nSummarizing batch of papers 1  papers\nget_cluster_summary prompt: 2140\nTitle: Scalable Image Coding Bridging Machine and Human Vision in Geospatial Applications\nreturning sections  [{'title': 'General Outlook', 'summary': 'This research addresses the dual need for image compression optimized for both machine vision tasks (like automated analysis of satellite imagery) and human visual perception within the Geospatial & Remote Sensing field. The core contribution involves developing scalable image coding techniques. Specifically, it introduces a novel method leveraging diffusion models, guided by the output of machine-focused compression (Image Coding for Machines - ICM), to generate human-viewable images from compact representations. This acts as an efficient bridge between machine and human vision needs, enabling the reconstruction of images suitable for human interpretation from data primarily compressed for AI analysis, without incurring additional bitrate overhead. This approach promises more efficient storage, transmission, and versatile use of geospatial image data for both automated systems and human analysts.', 'papers': [{'id': '2503.17907', 'summary': 'While the abstract does not explicitly mention geospatial applications, image compression and efficient storage/transmission are generally relevant to remote sensing and satellite imagery, as they deal with large image datasets. The focus of the paper on image compression techniques could find relevance in handling satellite or aerial imagery.', 'title': 'Guided Diffusion for the Extension of Machine Vision to Human Visual\\n  Perception'}]}]\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[{'industry': 'Entertainment & Media',\n  'sections': [{'title': 'General Outlook',\n    'summary': \"These studies highlight AI's role in advancing media creation and processing for entertainment. A common thread is the use of novel AI techniques, including generative models like diffusion and 3D Gaussian representations, to enhance visual content. Key contributions focus on generating higher-quality, more realistic, and specialized media formats, such as dynamic 3D scenes with complex lighting, human-perceivable images derived from machine-optimized data, and videos incorporating transparency for visual effects. The research emphasizes improving efficiency, enabling real-time performance in rendering and optimizing data transmission through scalable coding. Furthermore, these approaches offer enhanced control and integration capabilities, bridging different data types or generation methods to meet specific industry demands in areas like gaming, visual effects, and content delivery.\",\n    'papers': [{'id': '2503.17897',\n      'summary': 'The paper presents a real-time global illumination approach for dynamic 3D Gaussian models and meshes. This is relevant to the entertainment and media industry as it enables high-quality, real-time rendering of dynamic scenes with interactive materials and dynamic lighting, which is crucial for games, animation, and film.',\n      'title': 'Real-time Global Illumination for Dynamic 3D Gaussian Scenes'},\n     {'id': '2503.17907',\n      'summary': 'The paper discusses image compression techniques focused on both human perception and machine vision, with the goal of generating human-viewable images from compressed data using diffusion models. This is relevant to the Entertainment & Media industry because efficient image compression and generation are crucial for media streaming, content creation, and distribution, ultimately impacting user experience and cost-effectiveness.',\n      'title': 'Guided Diffusion for the Extension of Machine Vision to Human Visual\\n  Perception'},\n     {'id': '2503.17934',\n      'summary': 'The paper focuses on generating RGBA videos with alpha channels for transparency and visual effects. It mentions applications in gaming and visual effects, indicating a strong connection to the entertainment and media industry.',\n      'title': 'TransAnimate: Taming Layer Diffusion to Generate RGBA Video'}]}]},\n {'industry': 'Finance & Banking',\n  'sections': [{'title': 'General Outlook',\n    'summary': 'These research efforts contribute significantly to Finance & Banking by advancing the generation and application of synthetic market data. They employ sophisticated generative techniques, like diffusion models enhanced with retrieval methods, to create highly realistic, adaptable, and controllable market simulations across various conditions and frequencies. This addresses limitations of real-world data availability and the specificity of existing simulators. The core impact lies in enabling more robust development, testing, and optimization of downstream quantitative models, such as trading algorithms or risk assessment tools. By allowing for stress testing and the exploration of specific \"what-if\" scenarios within these advanced simulations, particularly under volatile or unprecedented conditions, the research aims to improve model performance, adaptability, and overall risk management within the financial sector.',\n    'papers': [{'id': '2503.17909',\n      'summary': 'The paper focuses on developing a market simulator for generating synthetic financial data, enhancing model development, and enabling stress testing for improved returns and risk control in complex market conditions. The core focus is on financial markets and applications of simulation in finance and banking.',\n      'title': 'Financial Wind Tunnel: A Retrieval-Augmented Market Simulator'}]}]},\n {'industry': 'Healthcare',\n  'sections': [{'title': 'General Outlook',\n    'summary': \"These research efforts commonly contribute novel AI frameworks and methods to improve clinical relevance and performance in healthcare. They utilize advanced models like Large Language Models (LLMs) and State Space Models to tackle specific challenges. A shared focus is enhancing AI's reasoning capabilities by incorporating deeper context. This includes structuring AI workflows to better align with clinical practices (e.g., sequential reasoning for treatment planning) and integrating patient-specific information or similar case experiences derived from Electronic Health Records (EHRs) via techniques like retrieval-augmented generation (RAG). By moving beyond general knowledge or simplistic processing, these approaches aim to make AI outputs more accurate, reliable, and grounded in real-world clinical data, ultimately improving applications like treatment planning, medical question answering, and anomaly detection in biomedical data.\",\n    'papers': [{'id': '2503.17900',\n      'summary': 'The paper focuses on generating personalized medical plans using LLMs, addressing the limitations of current systems in treatment planning from electronic health records. It proposes a two-stage RAG-based system (MedPlan) that aligns with clinical workflows and improves assessment accuracy and treatment plan quality.',\n      'title': 'MedPlan:A Two-Stage RAG-Based System for Personalized Medical Plan\\n  Generation'},\n     {'id': '2503.17903',\n      'summary': 'The paper introduces GLADMamba, a novel framework for unsupervised graph-level anomaly detection (UGLAD), with applications in anti-cancer drug discovery. It improves anomaly detection by using a selective state space model to capture long-range dependencies and spectral information, which is useful in the healthcare domain for identifying anomalies in complex biological networks and drug discovery processes.',\n      'title': 'GLADMamba: Unsupervised Graph-Level Anomaly Detection Powered by\\n  Selective State Space Model'},\n     {'id': '2503.17933',\n      'summary': \"This paper focuses on improving the reliability of Large Language Models (LLMs) in clinical applications by using retrieval-augmented generation (RAG) with Electronic Health Records (EHR). It introduces a framework called ExpRAG that retrieves relevant context from other patients' discharge reports to enhance medical reasoning. The paper also introduces a new clinical QA dataset called DischargeQA for evaluation. This is highly relevant to the healthcare industry as it directly addresses improving the accuracy and reliability of AI in medical applications, specifically for discharge quality assurance.\",\n      'title': 'Experience Retrieval-Augmentation with Electronic Health Records Enables\\n  Accurate Discharge QA'}]}]},\n {'industry': 'Manufacturing',\n  'sections': [{'title': 'General Outlook',\n    'summary': 'This research applies Machine Learning (ML), often integrated with domain-specific methods like Group Contribution (GC), to improve material design relevant to manufacturing. The core contribution involves developing tailored predictive models for key physical properties of specific substances, such as refrigerants. By utilizing curated databases and specialized ML models, this approach enables more accurate property prediction compared to general methods. This enhanced capability accelerates the design of novel materials and optimizes the performance of associated industrial systems, fostering efficiency and innovation within manufacturing contexts.',\n    'papers': [{'id': '2503.17919',\n      'summary': 'Refrigeration is used in some manufacturing processes, especially food related. The paper has a possible contribution to better selection of refrigerants in these use cases.',\n      'title': 'Predicting performance-related properties of refrigerant based on\\n  tailored small-molecule functional group contribution'}]}]},\n {'industry': 'Social Sciences & Humanities',\n  'sections': [{'title': 'General Outlook',\n    'summary': 'This research contributes advanced AI techniques for graph-level anomaly detection, directly applicable to social network analysis within the Social Sciences. By introducing methods like selective state space models (Mamba) combined with spectral information analysis, it offers enhanced capabilities for identifying unusual patterns, outliers, or structural deviations in complex network data. This advancement provides social scientists with more powerful computational tools to analyze large-scale social structures, potentially revealing hidden dynamics, influential nodes, or anomalous group behaviors that might be missed by traditional methods. The core contribution lies in improving the technical capacity for network analysis relevant to SSH research.',\n    'papers': [{'id': '2503.17903',\n      'summary': 'The paper introduces GLADMamba, a novel framework for unsupervised graph-level anomaly detection (UGLAD), with applications in social network analysis. It improves anomaly detection by using a selective state space model to capture long-range dependencies and spectral information, which is useful in the social sciences domain for identifying anomalies in complex social networks.',\n      'title': 'GLADMamba: Unsupervised Graph-Level Anomaly Detection Powered by\\n  Selective State Space Model'}]}]},\n {'industry': 'Energy & Utilities',\n  'sections': [{'title': 'General Outlook',\n    'summary': 'Research integrates machine learning (ML) with domain-specific methods, like group contribution (GC), to enhance the prediction of material properties critical to the Energy & Utilities sector. By tailoring models specifically for relevant substances, such as refrigerants, this approach overcomes limitations of general predictive methods, leading to more accurate estimations for specific molecule types. The common contribution lies in developing specialized AI-driven tools that accurately forecast key performance-related properties (e.g., boiling point, critical parameters). This improved predictive capability directly supports the design and discovery of novel materials and the optimization of energy systems, ultimately aiming to improve operational efficiency within the sector.',\n    'papers': [{'id': '2503.17919',\n      'summary': 'This paper focuses on predicting the performance-related properties of refrigerants, which are crucial for the design and optimization of refrigeration systems. Refrigeration systems are extensively used in the energy and utilities sector for various applications like cooling power plants, maintaining temperature in data centers, and transporting liquefied natural gas. The paper proposes a tailored group contribution (GC) method combined with machine learning to model key properties related to the operational efficiency of refrigeration systems, such as normal boiling point, critical temperature, critical pressure, enthalpy of vaporization, and acentric factor. This research has the potential to improve the efficiency and performance of refrigeration systems used in the energy and utilities industry, by enabling better refrigerant design and selection.',\n      'title': 'Predicting performance-related properties of refrigerant based on\\n  tailored small-molecule functional group contribution'}]}]},\n {'industry': 'Construction & Real Estate',\n  'sections': [{'title': 'General Outlook',\n    'summary': 'AI research contributes significantly to enhancing real-time 3D visualization capabilities applicable to the Construction and Real Estate industries. Key advancements focus on developing high-fidelity rendering techniques, such as real-time global illumination for complex 3D models including meshes and newer representations like 3D Gaussians. These methods enable the creation of dynamic, interactive digital environments where lighting conditions and material properties can be manipulated in real-time. This improves the realism and usability of architectural visualizations, virtual property tours, design simulations, and digital twins, facilitating better design exploration, stakeholder communication, and project understanding by providing high-performance, interactive rendering of complex scenes.',\n    'papers': [{'id': '2503.17897',\n      'summary': 'The paper presents a real-time global illumination approach for dynamic 3D Gaussian models and meshes. This could be used to render building designs in real time, which could be useful in the construction and real estate industries.',\n      'title': 'Real-time Global Illumination for Dynamic 3D Gaussian Scenes'}]}]},\n {'industry': 'Cybersecurity',\n  'sections': [{'title': 'General Outlook',\n    'summary': \"This research contributes an efficient, integrated defense mechanism for Large Language Models (LLMs) against jailbreak attacks. The core innovation is a lightweight framework enabling real-time detection of malicious prompts designed to bypass safety protocols. By leveraging the LLM's inherent capabilities via a novel single-token sentinel mechanism and combining supervised fine-tuning with adversarial training, the approach effectively identifies diverse jailbreak attempts. This method provides robust protection while preserving the LLM's utility on legitimate tasks and minimizing computational overhead. It offers a practical solution for enhancing the security and trustworthiness of deployed LLMs, addressing a critical vulnerability in AI systems relevant to cybersecurity.\",\n    'papers': [{'id': '2503.17932',\n      'summary': 'The paper addresses the vulnerability of Large Language Models (LLMs) to jailbreak attacks, which is a significant cybersecurity concern. It proposes a lightweight framework, STShield, for real-time detection of these attacks. This directly contributes to enhancing the security and robustness of LLMs against malicious attempts to bypass their safety mechanisms.',\n      'title': 'STShield: Single-Token Sentinel for Real-Time Jailbreak Detection in\\n  Large Language Models'}]}]},\n {'industry': 'Geospatial & Remote Sensing',\n  'sections': [{'title': 'General Outlook',\n    'summary': 'This research addresses the dual need for image compression optimized for both machine vision tasks (like automated analysis of satellite imagery) and human visual perception within the Geospatial & Remote Sensing field. The core contribution involves developing scalable image coding techniques. Specifically, it introduces a novel method leveraging diffusion models, guided by the output of machine-focused compression (Image Coding for Machines - ICM), to generate human-viewable images from compact representations. This acts as an efficient bridge between machine and human vision needs, enabling the reconstruction of images suitable for human interpretation from data primarily compressed for AI analysis, without incurring additional bitrate overhead. This approach promises more efficient storage, transmission, and versatile use of geospatial image data for both automated systems and human analysts.',\n    'papers': [{'id': '2503.17907',\n      'summary': 'While the abstract does not explicitly mention geospatial applications, image compression and efficient storage/transmission are generally relevant to remote sensing and satellite imagery, as they deal with large image datasets. The focus of the paper on image compression techniques could find relevance in handling satellite or aerial imagery.',\n      'title': 'Guided Diffusion for the Extension of Machine Vision to Human Visual\\n  Perception'}]}]}]"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"Finally, we want to output an HTML file that allows us to preview the data in a more user-friendly way.","metadata":{}},{"cell_type":"code","source":"from utils import report \nreport.generate_html_report(\n    os.path.join(config['out_dir'], 'industry_sections.json'),\n    os.path.join(config['out_dir'], 'final_report.html')\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T00:07:41.469979Z","iopub.execute_input":"2025-04-21T00:07:41.470338Z","iopub.status.idle":"2025-04-21T00:07:41.476321Z","shell.execute_reply.started":"2025-04-21T00:07:41.470315Z","shell.execute_reply":"2025-04-21T00:07:41.475589Z"}},"outputs":[{"name":"stdout","text":"✅ Report generated: /kaggle/working/final_report.html\n","output_type":"stream"}],"execution_count":20}]}